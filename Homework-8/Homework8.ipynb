{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "GfUGX45gmUDu",
        "outputId": "aaa86cd8-8428-495a-d67e-c3682bca5fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (48842, 15)\n",
            "Cleaned shape after dropping NaNs: (30162, 15)\n",
            "Number of features after encoding: 104\n",
            "Training data size (80%): 24129\n",
            "Test data size (20%): 6033\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,785\u001b[0m (26.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,785</span> (26.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,785\u001b[0m (26.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,785</span> (26.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the MLP model (50 epochs)...\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Test Data Accuracy after 50 epochs: 84.3030%\n",
            "Test Data Loss after 50 epochs: 0.3462\n",
            "\n",
            "--- New Sample Prediction ---\n",
            "New Sample Data:\n",
            "  age: 42\n",
            "  workclass: State-gov\n",
            "  fnlwgt: 57223\n",
            "  education: Bachelors\n",
            "  education-num: 13\n",
            "  marital-status: Never-married\n",
            "  occupation: Adm-clerical\n",
            "  relationship: Not-in-family\n",
            "  race: White\n",
            "  sex: Female\n",
            "  capital-gain: 2714\n",
            "  capital-loss: 0\n",
            "  hours-per-week: 40\n",
            "  native-country: United-States\n",
            "\n",
            "Predicted probability that the person’s income is greater than $50K/yr: 0.0152\n",
            "Predicted Class (1 for >$50K, 0 for <=$50K): 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "\n",
        "# --- 1. Load and Clean Data ---\n",
        "# Load the dataset. We assume the 'AdultUCI.csv' file is in the same directory.\n",
        "# The data description suggests some columns might have trailing spaces/periods.\n",
        "# We will use the 'na_values' parameter to treat ' ?' (common in this dataset) as NaN,\n",
        "# although the initial snippet didn't show it, it is a common issue with this dataset.\n",
        "try:\n",
        "    # Using the 'python' engine for potentially better handling of irregular lines\n",
        "    df = pd.read_csv('AdultUCI.csv', skipinitialspace=True, na_values=['?'], engine='python')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'AdultUCI.csv' not found. Please ensure the file is in the correct path.\")\n",
        "    exit()\n",
        "\n",
        "# The dataset snippet shows 'NA' in the income column for some rows.\n",
        "# Let's check for and remove rows with missing values, as requested.\n",
        "# We strip whitespace from all string columns to ensure proper cleaning and encoding.\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = df[col].str.strip()\n",
        "    # Replace ' ?' values found in some columns with NaN\n",
        "    df[col] = df[col].replace('?', np.nan)\n",
        "\n",
        "# Drop all cases (rows) with empty values (NaNs)\n",
        "df_cleaned = df.dropna()\n",
        "print(f\"Original shape: {df.shape}\")\n",
        "print(f\"Cleaned shape after dropping NaNs: {df_cleaned.shape}\")\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df_cleaned.drop('income', axis=1)\n",
        "# The target variable needs to be binary: 1 for >50K, 0 for <=50K.\n",
        "# Based on the snippet 'small' seems to be <=50K and 'large' or implied >50K.\n",
        "# We'll map the income column to 0 and 1. 'small' or '<=50K' to 0, and the rest ('>50K') to 1.\n",
        "# The actual labels in this specific file are often '<=50K' and '>50K', but\n",
        "# the snippet shows 'small'. We'll check the unique values and map them.\n",
        "if '<=50K' in df_cleaned['income'].unique():\n",
        "    # Use standard labels if they exist\n",
        "    y = (df_cleaned['income'] == '>50K').astype(int)\n",
        "else:\n",
        "    # Use 'small' as a proxy for the lower income if standard labels aren't present\n",
        "    # Assuming 'small' means <=50K and anything else is >50K (or 'large' which isn't explicit but implied)\n",
        "    y = (df_cleaned['income'] != 'small').astype(int)\n",
        "\n",
        "# --- 2. Encode the numeric and categorical features appropriately ---\n",
        "\n",
        "# Identify feature types\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Define preprocessor: Standard Scaler for numeric, One-Hot Encoder for categorical\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (none in this case, but good practice)\n",
        ")\n",
        "\n",
        "# Fit and transform the data\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Determine the number of features after one-hot encoding\n",
        "input_dim = X_processed.shape[1]\n",
        "print(f\"Number of features after encoding: {input_dim}\")\n",
        "\n",
        "# --- 3. Split the dataset as training (80%) and test data (20%) ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Training data size (80%): {X_train.shape[0]}\")\n",
        "print(f\"Test data size (20%): {X_test.shape[0]}\")\n",
        "\n",
        "# --- 4. Build an MLP model with one hidden layer ---\n",
        "# A common choice for a binary classification hidden layer is a power of 2,\n",
        "# or a size between the input and output size. We'll use 64 nodes.\n",
        "# Output layer uses sigmoid for binary probability prediction.\n",
        "# Loss is binary_crossentropy, and the metric is accuracy.\n",
        "model = Sequential([\n",
        "    # Hidden layer: use ReLU activation, standard for hidden layers\n",
        "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "    # Output layer: 1 unit with sigmoid activation for probability\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[BinaryAccuracy(name='accuracy')])\n",
        "\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Train the model for 50 epochs\n",
        "print(\"\\nTraining the MLP model (50 epochs)...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=0, # Set to 1 or 2 to see training progress\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "# Report the accuracy on the test data after 50 epochs\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "test_accuracy = accuracy * 100\n",
        "print(f\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Test Data Accuracy after 50 epochs: {test_accuracy:.4f}%\")\n",
        "print(f\"Test Data Loss after 50 epochs: {loss:.4f}\")\n",
        "\n",
        "# --- 5. Predict the probability for a new sample ---\n",
        "new_sample_data = {\n",
        "    'age': 42,\n",
        "    'workclass': 'State-gov',\n",
        "    'fnlwgt': 57223,\n",
        "    'education': 'Bachelors',\n",
        "    'education-num': 13,\n",
        "    'marital-status': 'Never-married',\n",
        "    'occupation': 'Adm-clerical',\n",
        "    'relationship': 'Not-in-family',\n",
        "    'race': 'White',\n",
        "    'sex': 'Female',\n",
        "    'capital-gain': 2714,\n",
        "    'capital-loss': 0,\n",
        "    'hours-per-week': 40,\n",
        "    'native-country': 'United-States'\n",
        "}\n",
        "\n",
        "# Convert the new sample to a DataFrame\n",
        "new_sample = pd.DataFrame([new_sample_data])\n",
        "\n",
        "# Pre-process the new sample using the fitted preprocessor\n",
        "# The column order must match the training data before processing.\n",
        "# We explicitly define the columns here to ensure the order is correct.\n",
        "original_columns = X.columns.tolist()\n",
        "new_sample_processed = preprocessor.transform(new_sample[original_columns])\n",
        "\n",
        "# Predict the probability\n",
        "# The prediction returns the probability P(income > $50K)\n",
        "probability_prediction = model.predict(new_sample_processed, verbose=0)[0][0]\n",
        "\n",
        "print(f\"\\n--- New Sample Prediction ---\")\n",
        "print(f\"New Sample Data:\")\n",
        "for key, value in new_sample_data.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nPredicted probability that the person’s income is greater than $50K/yr: {probability_prediction:.4f}\")\n",
        "\n",
        "# Optional: Predict the class (0 or 1)\n",
        "predicted_class = (probability_prediction > 0.5).astype(int)\n",
        "print(f\"Predicted Class (1 for >$50K, 0 for <=$50K): {predicted_class}\")"
      ]
    }
  ]
}